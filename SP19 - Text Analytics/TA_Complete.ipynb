{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TA_Complete.ipynb","version":"0.3.2","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"metadata":{"id":"Y_laTAKPHShs","colab_type":"text"},"cell_type":"markdown","source":["![alt text](https://bdaaosu.org/img/Logo.png)"]},{"metadata":{"id":"PqFyLVd7Hodh","colab_type":"text"},"cell_type":"markdown","source":["# <center> Intro to Text Analytics with Python </center>\n","\n","---\n","\n"]},{"metadata":{"id":"jP4Lw78MHuaz","colab_type":"text"},"cell_type":"markdown","source":["## Importing packages / downloading stuff"]},{"metadata":{"id":"Rj5Y_XxbaZS6","colab_type":"text"},"cell_type":"markdown","source":["Packages are the backbone of Python. We'll need a couple very popular packages for our task, so let's install them and load them in."]},{"metadata":{"id":"ZevXNiIpHERj","colab_type":"code","colab":{}},"cell_type":"code","source":["import nltk\n","from nltk.tokenize import word_tokenize # Word tokenizer\n","from nltk.probability import FreqDist # Fistribution generator for token frequency\n","from nltk.corpus import stopwords # Stopwords\n","from nltk.stem.wordnet import WordNetLemmatizer # Lemmatizer using NLTK's \"wordnet\"\n","from nltk.stem.porter import PorterStemmer # Word stemmer\n","import gensim # LDA topic modeling\n","import pandas as pd # Data manipulation package; keystone python data science package\n","import matplotlib.pyplot as plt # Plotting function\n","import collections # Sort tokens by count\n","flatten = lambda l: [item for sublist in l for item in sublist]\n","import io\n","from google.colab import files"],"execution_count":0,"outputs":[]},{"metadata":{"id":"g8Dj1UNbLcDj","colab_type":"code","colab":{}},"cell_type":"code","source":["# The following statements are needed to download nltk \"data packages,\" \n","# which contain a lot of the material we'll need to use NLTK functions\n","nltk.download('punkt') # Sentence tokenizer data package\n","nltk.download('stopwords') # Stopwords data package\n","nltk.download('wordnet') # Wordnet (word associations) data package"],"execution_count":0,"outputs":[]},{"metadata":{"id":"GqueYCpdUUlc","colab_type":"text"},"cell_type":"markdown","source":["## Loading in the data: TED Talks!\n","\n","Find the data on GDrive here: [TED Talks Data](http://go.osu.edu/BDAA_TED_Data)\n","\n","Data source: [Kaggle Ted Talks Dataset](https://www.kaggle.com/rounakbanik/ted-talks#transcripts.csv)\n","\n","This dataset contains transcripts of 2,467 TED Talks from 2006 to 2017.\n","\n","Say that you want to find a few great ted talks in this dataset to digest. Where should you start? Reading through all >2,000 of them would be a little silly - you want to find some interesting talks to read/watch, _and fast_. To give better insight into where you should be directing your attention in the transcripts data, we'll see if we can programmatically find a set number of topics that you can start from, as well as create a model to drop any new transcripts you come across into these topic \"buckets\". "]},{"metadata":{"id":"r9uxyJo-IyQ7","colab_type":"code","colab":{}},"cell_type":"code","source":["uploaded = files.upload()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hNiYbC8fIZI3","colab_type":"code","colab":{}},"cell_type":"code","source":["# Pandas is great for reading in and manipulating CSV files!\n","ted = pd.read_csv(io.StringIO(uploaded['transcripts.csv'].decode('utf-8')))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"3SoaFRcg3Ng2","colab_type":"code","colab":{}},"cell_type":"code","source":["ted.transcript[0]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1lAfkjcKUlOp","colab_type":"text"},"cell_type":"markdown","source":["## Preprocessing the transcripts\n","\n","Before passing the transcripts into the tokenizer, we need to correct any inconsistencies in the text data. Before modeling, we need to investigate the transcripts to see if there's any artifacts that will not be relevant to our analysis. To do this, we need to understand how models are built based on the tokens that are generated from the transcripts."]},{"metadata":{"id":"QpTfUeOyQsSG","colab_type":"code","colab":{}},"cell_type":"code","source":["# Remove transcript \"artifacts,\" like talk queues or audience responses\n","# Use the apply() method on a DF series to apply a transformation to every data point in the series\n","ted['transcript'] = ted['transcript'].apply(lambda x: x.replace('(Laughter)', ' ').replace('(Applause)', ' ').replace('(Music)', ' ').replace('â™«', ' '))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NilkqXHxR_k6","colab_type":"code","colab":{}},"cell_type":"code","source":["## ANSWER 1\n","# Hint for statement #1: \"BDAA. Inspire. Empower. Connect.\".replace('. ', ' ') -> \"BDAA Inspire Empower Connect\"\n","# Hint for statement #2: \"BDAA Inspire Empower Connect\".lower() -> \"bdaa inspire empower connect\""],"execution_count":0,"outputs":[]},{"metadata":{"id":"e5McsJg_UqKZ","colab_type":"text"},"cell_type":"markdown","source":["## Tokenizing"]},{"metadata":{"id":"lOCTqwlAbYJz","colab_type":"text"},"cell_type":"markdown","source":["Many text analytics algorithms assume that input data (i.e. text) is _tokenized_. That is, we will be feeding a list/array of words or (what we, as data scientists, identify to be) meaningful tokens into our algorithms."]},{"metadata":{"id":"Xax71Yy3J-_Z","colab_type":"code","colab":{}},"cell_type":"code","source":["# Use the word_tokenize function from NLTK to tokenize the first transcript\n","ted_tokens = word_tokenize(ted.transcript[0])"],"execution_count":0,"outputs":[]},{"metadata":{"id":"AyU8Wx6WMHj6","colab_type":"code","colab":{}},"cell_type":"code","source":["# What do \"tokens\" look like?\n","ted_tokens"],"execution_count":0,"outputs":[]},{"metadata":{"id":"oRixGsF0Lp4g","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a frequency distribution of all tokens in the first transcript\n","fdist = FreqDist(ted_tokens)\n","print(fdist)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"n6VEKVb3LzKQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Plot the distribution! Matplotlib is perhaps the most popular visualization package in Python\n","fdist.plot(30,cumulative=False)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"sLF_sGJMUueN","colab_type":"text"},"cell_type":"markdown","source":["## Stopwords"]},{"metadata":{"id":"VnAuEGgpcleN","colab_type":"text"},"cell_type":"markdown","source":["The English language contains lots of rather meaningless words that only serve to glue _meaningful_ words together. \n","\n","Take the following two sentences, for example:\n","\n","> _\"I was just in Scott, trying to eat, when all the sudden a food fight broke out\"_\n","\n","> _\"I was just in the hospital, trying to diagnose a patient, when all the sudden a code blue came over the speaker\"_\n","\n","\n","What's the general topic of each sentence? Do the \"glue\" words help us determine what the topic is? When we're trying to model topics, these words won't do us any service. So, let's remove them! "]},{"metadata":{"id":"tYtWF0x6Mwdf","colab_type":"code","colab":{}},"cell_type":"code","source":["# NLTK has compiled a list of common stopwords that we can remove from our transcripts\n","stop_words=set(stopwords.words(\"english\"))\n","print(stop_words)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"NoLCP_YqNlu9","colab_type":"code","colab":{}},"cell_type":"code","source":["# Remove both stopwords and words with a character length less than 4 from our list of tokens\n","ted_tokens = [token for token in ted_tokens if token not in stop_words and len(token) > 4]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"0Y7kL5rSVnAz","colab_type":"code","colab":{}},"cell_type":"code","source":["ted_tokens"],"execution_count":0,"outputs":[]},{"metadata":{"id":"6M5ePSxQT_3N","colab_type":"text"},"cell_type":"markdown","source":["## Stemming / Lemmatization"]},{"metadata":{"id":"MELGNNq5ewty","colab_type":"text"},"cell_type":"markdown","source":["Because of all of the tenses and qualifiers, many of the verbs and nouns in the English language take several different forms, depending on context, but semantically convey the same idea.\n","\n","Take the verb _break_ for example:\n","\n","> **Forms:** break, breaks, broke, broken, breaking\n","\n","Also, take the noun _person_:\n","\n","> **Forms:** person, people, personification\n","\n","Because these forms are different on a character by character level, however, a computer will not be able to discern that they are the same without background knowledge. This is where _stemming_ and _lemmatization_ come in. \n","\n","_Stemming_ removes common suffixes from words. Stemming will not change the base form of the word.\n","\n","<br>\n","![Stemming example](https://nlp.stanford.edu/IR-book/html/htmledition/img102.png)\n","<br>\n","\n","_Lemmatization_ involves a full morphilogical analysis to identify the correct _lemma_ (i.e. stem) of each word. It will change the base form of the word if necessary."]},{"metadata":{"id":"PeXUpAYOTkTQ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Import and create a Stemmer object\n","stem = PorterStemmer()\n","\n","# Import and create a Lemmatizer object\n","lem = WordNetLemmatizer()\n","\n","\n","word = \"flew\"\n","print(\"Stemmed Word:\",stem.stem(word))\n","print(\"Lemmatized Word:\",lem.lemmatize(word,\"v\"))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"Nfpy3lkAUh_a","colab_type":"code","outputId":"ae0c8826-52b9-4b29-f6ff-a64dd6502ef1","executionInfo":{"status":"error","timestamp":1550025710534,"user_tz":300,"elapsed":527,"user":{"displayName":"Mitch Radakovich","photoUrl":"https://lh5.googleusercontent.com/-nOLmj6ix-hk/AAAAAAAAAAI/AAAAAAAAAGo/W-9Lf-CzjdU/s64/photo.jpg","userId":"16791291129030414577"}},"colab":{"base_uri":"https://localhost:8080/","height":164}},"cell_type":"code","source":["[WordNetLemmatizer().lemmatize(token,\"v\") for token in ted_tokens]"],"execution_count":0,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-eeb495dcec6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;34m[\u001b[0m\u001b[0mWordNetLemmatizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtoken\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"v\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtoken\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mted_tokens\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'ted_tokens' is not defined"]}]},{"metadata":{"id":"mzBcsX1vUcdn","colab_type":"text"},"cell_type":"markdown","source":["## Cleaning up our tokens"]},{"metadata":{"id":"-RgEP93hiM3j","colab_type":"text"},"cell_type":"markdown","source":["Let's apply all the transformation operations to every transcript in the dataset, and save the resulting tokens in a _list of lists_."]},{"metadata":{"id":"my5l921eZKPR","colab_type":"code","colab":{}},"cell_type":"code","source":["text_data = []\n","\n","# Define a function to do the cleaning for us, given text data and a list of stopwords\n","def tokenize_and_clean(transcripts):\n","  \n","  data = []\n","  # Apply all cleaning operations to each transcript and append the resulting tokens to a \"list of lists\"\n","  for transcript in transcripts:\n","    ted_tokens = word_tokenize(transcript)\n","    ted_tokens = [token for token in ted_tokens if token not in stop_words and len(token) > 4]\n","    ted_tokens = [WordNetLemmatizer().lemmatize(token,\"v\") for token in ted_tokens]\n","    data.append(ted_tokens)\n","    \n","  return data\n","  \n","  \n","text_data = tokenize_and_clean(ted.transcript)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"vsM71JtaUf2V","colab_type":"text"},"cell_type":"markdown","source":["## Topic Modeling!"]},{"metadata":{"id":"tOo92Y21iqxJ","colab_type":"text"},"cell_type":"markdown","source":["Gensim is a _topic modeling framework_, or a suite of tools to convert tokenized data into \"corpuses\" to be used in _Latent Dirichlet Allocation_, the model to generate topics from transcript tokens.\n","\n"]},{"metadata":{"id":"mRHBE1w3XghT","colab_type":"code","colab":{}},"cell_type":"code","source":["# Convert the tokens to a dictionary format\n","dictionary = gensim.corpora.Dictionary(text_data)\n","dict(dictionary)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"zWQrTqDZWW7P","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a text \"corpus\" from each transcript\n","corpus = [dictionary.doc2bow(text) for text in text_data]\n","corpus[1870]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ea4Tzz4qj2R8","colab_type":"code","colab":{}},"cell_type":"code","source":["# How is the computer interpreting the words?\n","corpus_1870 = corpus[1870]\n","\n","for word_id in corpus_1870:\n","  print(\"Token {} (\\\"{}\\\") appears {} time(s).\".format(word_id[0], dictionary[word_id[0]], word_id[1]))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v0z70NeGjZuK","colab_type":"text"},"cell_type":"markdown","source":[""]},{"metadata":{"id":"ucH-iMZ0YzpM","colab_type":"code","colab":{}},"cell_type":"code","source":["NUM_TOPICS = 5\n","ldamodel = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"1DP32wrsY7KB","colab_type":"code","colab":{}},"cell_type":"code","source":["WORDS_PER_TOPIC = 7\n","topics = ldamodel.print_topics(num_words = WORDS_PER_TOPIC)\n","for topic in topics:\n","    print(topic)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hiwVYdAIU8xc","colab_type":"text"},"cell_type":"markdown","source":["Are these topics what we're looking for? Are the words associated with each topic informative?\n","\n","_Not really._\n","\n","What are the most common words across all transcripts?"]},{"metadata":{"id":"-wt6uekLsSUh","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a list of all tokens across transcripts\n","all_tokens = flatten(text_data)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"A2ILzmHBtnFo","colab_type":"code","colab":{}},"cell_type":"code","source":["# Create a frequency distribution of all tokens in all transcripts\n","fdist = FreqDist(all_tokens)\n","print(fdist)\n","# Plot the distribution! Matplotlib is perhaps the most popular visualization package in Python\n","fdist.plot(30,cumulative=False)\n","plt.show()"],"execution_count":0,"outputs":[]},{"metadata":{"id":"h-kQM6DEuMGZ","colab_type":"code","colab":{}},"cell_type":"code","source":["# Filter out any tokens that appear in more than 50% of the transcripts\n","dictionary.filter_extremes(no_above = 0.5)\n","corpus = [dictionary.doc2bow(text) for text in text_data]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"5hvu3DWGxaD-","colab_type":"code","colab":{}},"cell_type":"code","source":["# Retrain the model!\n","NUM_TOPICS = 5\n","lda_model = gensim.models.ldamodel.LdaModel(corpus, num_topics = NUM_TOPICS, id2word=dictionary, passes=15)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"dh-6jdPcxc18","colab_type":"code","colab":{}},"cell_type":"code","source":["WORDS_PER_TOPIC = 7\n","topics = ldamodel.print_topics(num_words = WORDS_PER_TOPIC)\n","for topic in topics:\n","    print(topic)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"T77URgcOror3","colab_type":"text"},"cell_type":"markdown","source":["## Model Evaluation"]},{"metadata":{"id":"j3mWLjjDrrxl","colab_type":"text"},"cell_type":"markdown","source":["How is our model generating topic \"scores\" under the hood? How does it react to transcripts it has never seen before?"]},{"metadata":{"id":"V9OpxDq6qxz3","colab_type":"code","colab":{}},"cell_type":"code","source":["ted.loc[1870]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SiBBjrqFqEjY","colab_type":"code","colab":{}},"cell_type":"code","source":["# Let's evaulate our model's performance. How is it generating topic \"scores\" for each transcript?\n","for index, score in sorted(ldamodel[corpus[1870]], key = lambda x: -1*x[1]):\n","  print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, ldamodel.print_topic(index, 10)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"SNjK_V_hrOcA","colab_type":"code","colab":{}},"cell_type":"code","source":["# How does our model react to a transcript it hasn't seen yet?\n","ts = \"\"\"\n","to do two things at once is to do\n","neither it's great smack down of\n","multitasking isn't it often attributed\n","to the Roman writer probably leus serous\n","although you know how these things are\n","he probably never said it what I'm\n","interested in though is is it true I\n","mean it's obviously true for emailing at\n","the dinner table or texting while\n","driving or possibly for live tweeting a\n","TED talk as well but I'd like to argue\n","that for an important kind of activity\n","doing two things at once all three you\n","even four is exactly what we should be\n","aiming for look no further than Albert\n","Einstein in 1905 he published four\n","remarkable scientific papers one of them\n","was on Brownian motion it provided\n","empirical evidence that atoms exist and\n","it laid out the basic mathematics behind\n","most of financial economics another one\n","was on the theory of special relativity\n","another one was on the photoelectric\n","effect\n","that's why solar panels work it's a nice\n","one gave him the Nobel Prize for that\n","one and the fourth introduced an\n","equation you might have heard of e\n","equals MC squared so tell me again how\n","you shouldn't do several things at once\n","now obviously working simultaneously on\n","Brownian motion special relativity in\n","the photoelectric effect it's not\n","exactly the same kind of multitasking a\n","snapchatting while you're watching\n","Westworld a very different and einstein\n","well Einsteins he's Einstein was one of\n","a kind he's unique but the pattern of\n","behavior that Einstein was demonstrating\n","that's not unique at all it's very\n","common among highly creative people both\n","artists and scientists and I'd like to\n","give it a name slow motion multitasking\n","slow motion multitasking feels like a\n","counterintuitive idea what I'm\n","describing here is having multi\n","projects on the go at the same time when\n","you move backwards and forwards between\n","topics as the mood takes you or as the\n","situation demands but the reason it\n","seems counterintuitive is because we're\n","used to lapsing into multitasking out of\n","desperation we're in a hurry who want to\n","do everything at once if we were willing\n","to slow multitasking down we might find\n","that it works quite brilliantly 60 years\n","ago a young psychologist by the name of\n","Bernice a Jason began a long research\n","project into the personalities and the\n","working habits of 40 leading scientists\n","Einstein was already dead but four of\n","her subjects won Nobel prizes including\n","Linus Pauling and Richard Feynman the\n","research went on for decades in fact it\n","continued even after professor Aegis and\n","herself had died and one of the\n","questions that it answered was how is it\n","that some scientists are able to go on\n","producing important work right through\n","their lives what is it about these\n","people is it their personality is their\n","skillset their daily routines oh well\n","the pattern that emerged was clear and I\n","think to some people surprising the top\n","scientists kept changing the subject\n","they would shift topics repeatedly\n","during their first hundred published\n","research papers you want to guess how\n","often three times five times no\n","on average the most enduringly creative\n","scientists switched topics 43 times in\n","their first hundred research papers\n","seems that the secret to creativity is\n","multitasking in slow motion her a\n","Jason's research suggests we need to\n","reclaim multitasking and remind\n","ourselves how powerful it can be and\n","she's not the only person to have found\n","this different researchers using\n","different methods to study different\n","highly creative people have found that\n","very often\n","have multiple projects in progress at\n","the same time and they're also far more\n","likely than most of us to have serious\n","hobbies slow motion multitasking among\n","creative people is ubiquitous so why I\n","think there were three reasons and the\n","first is the simplest a creativity often\n","comes when you take an idea from its\n","original context and you move it\n","somewhere else it's easier to think\n","outside the box if you spend your time\n","clambering from one box into another for\n","an example of this consider the original\n","Eureka moment Archimedes is wrestling\n","with a difficult problem and he realizes\n","in a flash he can solve it using the\n","displacement of water and if you believe\n","the story this idea comes to him as he's\n","taking a bath lowering himself in and\n","he's watching the water level rise and\n","fall and if solving a problem while\n","having a bath isn't multitasking I don't\n","know what is the second reason that\n","multitasking can work is that learning\n","to do one thing well can often help you\n","do something else\n","any athlete can tell you about the\n","benefits of cross-training it's possible\n","to cross train your mind to a few years\n","ago researchers took 18 randomly chosen\n","medical students and they enrolled them\n","in a course at the Philadelphia Museum\n","of Art where they learned to criticise\n","and analyze works of visual art and at\n","the end of the course these students\n","were compared with a control group of\n","their fellow medical students and the\n","ones who had taken the art course had\n","become substantially better at\n","performing tasks such as diagnosing\n","diseases of the eye by analyzing\n","photographs\n","they've become better eye doctors so if\n","we want to become better what we do\n","maybe we should spend some time doing\n","something else even if the two fields\n","appear to be as completely distinct as\n","ophthalmology and the history of art and\n","if you'd like an example of this should\n","we go for a less intimidating example\n","and\n","okay michael crichton creator of\n","Jurassic Park and ER so in the 1970s he\n","originally trained as a doctor but then\n","he wrote novels and he directed the\n","original Westworld movie but also and\n","this is less well known\n","he also wrote non-fiction books about\n","art medicine that computer programming\n","so in 1995 he enjoyed the fruits of all\n","this variety by penning the world's most\n","commercially successful book and the\n","world's most commercially successful TV\n","series and the world's most commercially\n","successful movie in 1996 he did it all\n","over again there's a third reason why\n","slow motion multitasking can help us\n","solve problems it can provide assistance\n","when we're stuck this can happen in an\n","instant so imagine that feeling of\n","working on a crossword puzzle and you\n","can't figure out the answer and the\n","reason you can't is because the wrong\n","answer is stuck in your head it's very\n","easy just go and do something else here\n","switch topics switch context you'll\n","forget the wrong answer and that gives\n","the right answer space to pop into the\n","front of your mind but on the slower\n","time scale that interests me being stuck\n","is a much more serious thing yeah you\n","you get turned down for funding these\n","cell cultures won't grow your rockets\n","keep crashing nobody wants to publish\n","your fantasy novel about a school for\n","wizards or maybe you just can't find a\n","solution to the problem that you're\n","working on and being stuck like that\n","I mean stasis stress possibly even\n","depression but if you have another\n","exciting challenging project to work on\n","or being stuck on one it's just an\n","opportunity to do something else we\n","could all get stuck sometimes even\n","Albert Einstein ten years after the\n","original miraculous year that I\n","described\n","Einstein was putting together the pieces\n","of his theory of general\n","Relativity his greatest achievement and\n","he was exhausted and so he turned to an\n","easier problem he proposed the\n","stimulated emission of radiation which\n","as you may know is the sir in laser so\n","he's laying down the theoretical\n","foundation for the laser beam and then\n","while he's doing that he moves back to\n","general relativity and he's refreshed he\n","sees what the theory implies that the\n","universe isn't static it's expanding\n","it's an idea so staggering Einstein\n","can't bring himself to believe it for\n","years look if you get started and you\n","lay the book you get the ball rolling on\n","laser beams you're in pretty good shape\n","so that's the case for slow motion\n","multitasking you know I'm not promising\n","that it's going to turn you into\n","Einstein\n","I'm not even promising it's going to\n","turn you into Mach Michael Crichton but\n","it is a powerful way to organize our\n","creative lives but there's a problem how\n","do we stop all of these projects\n","becoming completely overwhelming how do\n","we keep all these ideas straight in our\n","minds well here's a simple solution a\n","practical solution from the great\n","American choreographer Twyla Tharp over\n","the last few decades\n","she's blurred boundaries mixed genres\n","won prizes danced to the music of\n","everybody from Philip Glass to Billy\n","Joel she's written three books I mean\n","she's a Jesus slow-motion multitasker of\n","course she is she says you have to be\n","all things why exclude you have to be\n","everything and thoughts method for\n","preventing all of these different\n","projects from becoming overwhelming is a\n","simple one she gives each project a big\n","cardboard box writes the name of the\n","project on the side of the box and into\n","it she tosses DVDs and books magazine\n","cuttings\n","theater programs physical objects really\n","anything that's provided a source of\n","creative inspiration and she writes the\n","Box means I never have to worry about\n","forgetting one of the biggest fears for\n","a creative person is that some brilliant\n","idea will get lost because you didn't\n","write it down and put it in a safe place\n","I don't worry about that because I know\n","where to find it it's all in the box you\n","can manage many ideas like this either\n","in physical boxes or in their digital\n","equivalents so I would like to urge you\n","to embrace the art of slow motion\n","multitasking not because you're in a\n","hurry but because you're in no hurry at\n","all and I want to give you one final\n","example my favorite example Charles\n","Darwin a man whose slow-burning\n","multitasking is so staggering and he's a\n","diagram to explain it all to you\n","we know what Darwin was doing at\n","different times because the creativity\n","researchers Howard Gruber and Sarah\n","Davis have analyzed his Diaries and his\n","notebooks so when he left school age of\n","18 he was initially interested in two\n","fields\n","so it's zoology and geology pretty soon\n","he signed up to be the on board\n","naturalist on the Beagle this is the the\n","ship that eventually took five years to\n","sail all the way around the southern\n","oceans of the earth stopping at the Gila\n","Africa's passing through the Indian\n","Ocean while he was on the Beagle he\n","began researching coral reefs this is a\n","great synergy between his two interests\n","in zoology and geology and it starts to\n","get him thinking about slow processes\n","but when he gets back from the voyage\n","his interests start to expand even\n","further psychology botany for the rest\n","of his life he's moving backwards and\n","forwards between these different fields\n","he never quite abandons any of them in\n","1837 he begins work on two very\n","interesting projects one of them\n","earthworms\n","the other a little notebook which he\n","titles the transmutation of species then\n","Darwin starts studying my field\n","economics he reads a book by the\n","economist Thomas Malthus and he has his\n","Eureka moment in a flash he realizes how\n","species could emerge and evolve slowly\n","through this process of the survival of\n","the fittest\n","it all comes to him he writes it all\n","down every single important element of\n","the theory of evolution in that notebook\n","but then a new project is some Williams\n","born well as a natural experiment right\n","there you get to observe the development\n","of a human infant so immediately Darwin\n","starts making notes now of course he's\n","still working on a theory of evolution\n","and the development of the human infant\n","but during all of this he realizes he\n","doesn't really know enough about\n","taxonomy they starts studying that and\n","in the end he spends eight years\n","becoming the world's leading expert on\n","barnacles then natural selection a book\n","that he's to continue working on for his\n","entire life he never finishes it Origin\n","of Species is finally published twenty\n","years after Darwin sent out all the\n","basic elements then the descent a man\n","controversial book and then the book\n","about the development of the human\n","infant the one that was inspired when it\n","would he could see his son William\n","crawling on the the sitting room floor\n","in front of him when the book was\n","published\n","William was 37 years old and all this\n","time\n","Darwin's working on earthworms he fills\n","his billiard room with earthworms in\n","pots with gas covers he shines lights on\n","them to see if they'll respond\n","he holds a hot poker next and see if\n","they move away he chews tobacco and he\n","blows on the earthworms to see if they\n","have a sense of smell he even plays the\n","bassoon at the earthworms\n","I like to think of this great man when\n","he's tired he's stressed he's anxious\n","about the reception of his book The\n","Descent of Man you or I might log into\n","Facebook or turn on the television\n","Darwin would go into the billiard room\n","to relax by studying the earthworm's\n","intensely and that's why it's\n","appropriate that one of his last great\n","works is the formation of vegetable\n","mould through the action of worms\n","he worked upon that book for 44 years we\n","don't live in the 19th century anymore I\n","don't think any of us could sit on our\n","creative or scientific projects for 44\n","years but we do have something to learn\n","from the great slow motion multitaskers\n","from Einstein and Darwin to Michael\n","Crichton and Twyla Tharp the modern\n","world seems to present us with a choice\n","if we're not get a fast twitch from\n","browser window to browser window we have\n","to live like a hermit focus on one thing\n","to the exclusion of everything else I\n","think that's a false dilemma we can make\n","multitasking work for us unleashing our\n","natural creativity we just need to slow\n","it down so make a list of your projects\n","put down your phone pick up a couple of\n","cardboard boxes and get to work thank\n","you very much\n","[Applause]\n","\"\"\"\n","ts = ts.replace('[Applause]', ' ').replace('[Laughter]', ' ').replace('[Applause]', ' ')\n","ts = ts.replace('. ', ' ').lower()\n","\n","ts_list = []\n","ts_list.append(ts)\n","test_tokens = tokenize_and_clean(ts_list)"],"execution_count":0,"outputs":[]},{"metadata":{"id":"ur0hjCqqstbn","colab_type":"code","colab":{}},"cell_type":"code","source":["# Make sure the tokens look okay before proceeding!\n","test_tokens"],"execution_count":0,"outputs":[]},{"metadata":{"id":"v_8si4GktNvM","colab_type":"code","colab":{}},"cell_type":"code","source":["# We'll need to create another corpus for our test transcript\n","test_corpus = [dictionary.doc2bow(text) for text in text_data]"],"execution_count":0,"outputs":[]},{"metadata":{"id":"OQaFc1QstWIu","colab_type":"code","colab":{}},"cell_type":"code","source":["# How does the model perform on test data?\n","for index, score in sorted(ldamodel[test_corpus[0]], key = lambda x: -1*x[1]):\n","  print(\"\\nScore: {} \\nTopic: {}\".format(score, ldamodel.print_topic(index, 10)))"],"execution_count":0,"outputs":[]},{"metadata":{"id":"hGRWRuRj4xH5","colab_type":"text"},"cell_type":"markdown","source":["# Answers"]},{"metadata":{"id":"0FVX3U3H4v8a","colab_type":"code","colab":{}},"cell_type":"code","source":["# ANSWER 1\n","# Fix an odd inconsistency in the transcript data, and convert all transcripts to lowercase\n","ted['transcript'] = ted['transcript'].apply(lambda x: x.replace('.', ' '))\n","ted['transcript'] = ted['transcript'].apply(lambda x: x.lower())"],"execution_count":0,"outputs":[]},{"metadata":{"id":"CKYSB72Wt1At","colab_type":"text"},"cell_type":"markdown","source":["# Resources"]},{"metadata":{"id":"UR660QfJt2_-","colab_type":"text"},"cell_type":"markdown","source":["> [DataCamp](https://www.datacamp.com/community/tutorials/text-analytics-beginners-nltk)\n","\n","> [AnalyticsVidhya](https://www.analyticsvidhya.com/blog/2018/02/the-different-methods-deal-text-data-predictive-python/)\n","\n","> [Coursera](https://www.coursera.org/learn/python-text-mining)"]}]}