{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Exploratory Data Analysis in Python <h1>\n",
    "    <img src=\"https://bdaaosu.org/static/img/Logo.png\" width=\"40%\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was prepared and created by [Leo Glowacki](http://www.leoglowacki.com). Any questions can be sent through (preferably) the BDAA slack or through the <a href=\"http://www.leoglowacki.com/contact\">contact form on my website</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing Packages </h3>  \n",
    "\n",
    "First things first- importing packages. We'll be using:\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) - library for data manipulation and analysis\n",
    "\n",
    "[Plotly Express](https://plot.ly/python/plotly-express/) - new high-level visualization library\n",
    "\n",
    "You will likely need to add Plotly Express to your Anaconda environment. Most common data science packages come included with Anaconda, however, Plotly Express is new and not included. We'll do this together. ([Instructions if you need them later](https://www.tutorialspoint.com/add-packages-to-anaconda-environment-in-python))\n",
    "\n",
    "If you are having any issues intalling or updating packages in your Anaconda environment, this is a reported issue. Luckily, there is a [fix (scroll to bottom)](https://github.com/ContinuumIO/anaconda-issues/issues/9087). Ask a TA if you need help! It can be a little confusing if you haven't worked with Anaconda before. \n",
    "\n",
    "To import a package:\n",
    "\n",
    "`import package_name` <br>\n",
    "OR <br>\n",
    "`import package_name as nickname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas\n",
    "import pandas as pd\n",
    "# suppress scientific notation (not necessary, but useful here)\n",
    "pd.options.display.float_format = '{:.2f}'.format\n",
    "# add to anaconda environment\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Reading in our Dataset </h3>\n",
    "\n",
    "Now we want to import our youtube video data.\n",
    "\n",
    "[Dataset Info](https://www.kaggle.com/datasnaek/youtube-new#USvideos.csv)\n",
    "\n",
    "[Download the Dataset Here](https://www.kaggle.com/datasnaek/youtube-new/download/ZGIimwlwh1EQ13BoyAyJ%2Fversions%2FHaqpEW6xcYnw6T0JDLWk%2Ffiles%2FUSvideos.csv?datasetVersionNumber=115)\n",
    "\n",
    "Make sure to unzip the file and move it into the same folder as this Jupyter notebook.\n",
    "\n",
    "Our dataset is \"USvideos.csv\"\n",
    "\n",
    "CSV: Comma-separated values:\n",
    "- Each line of the file is a record/observation<br>\n",
    "- Each record/observation consists of one or more fields, separated by commas<br>\n",
    "\n",
    "Pandas has a way to import CSV files:\n",
    "\n",
    "`pandas.read_csv(filepath, ...)`\n",
    "\n",
    "This creates a 'dataframe'. Dataframes are essentially fancy tables stored in python.\n",
    "\n",
    "[Documentation: pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our CSV file as a pandas dataframe called 'data'\n",
    "# you will often see pandas dataframes called 'df'\n",
    "data = pd.read_csv(\"???.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view our dataframe\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the data types of our columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that 'trending_date' and 'publish_time' are being treated as objects instead of dates. Also, even though 'category_id' is a integer, it really functions as a discrete categorical variable instead of a continuous one. \n",
    "\n",
    "Let's do a little quick data cleaning..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing 'trending_date' and 'publish_time' to be dates\n",
    "data['trending_date'] = pd.to_datetime(data['trending_date'],format='%y.%d.%m')\n",
    "data['publish_time'] = pd.to_datetime(data['publish_time'])\n",
    "# making 'category_id' a categorical (factor) variable\n",
    "data['category_id'] = data['category_id'].astype('category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll also notice that when I edited this dataframe, I had to overwrite the previous dataframe. Typically, when running a function on a dataframe (`to_datetime` and `astype` in this example), the results are not saved to the dataframe you run it on. So, you have to save the result to your dataframe if you want it to persist. The benefit here is we can choose to assign the result to a brand new dataframe without messing up our original dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Basic Statistics in pandas </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get basic summary statistics on our data\n",
    "???.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of non-null values in each column\n",
    "???.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between columns\n",
    "???.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that 'likes' and 'views' have a positive correlation of 0.85. Additionally, 'likes' and 'comment_count' have a correlation of 0.80.  Interesting. We will come back to this later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Single Variable Plots </h3>\n",
    "\n",
    "[Documentation: Plotly Express](https://plot.ly/python/plotly-express/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x='likes')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of Comment Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(data, x=???)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Two Variable Plots </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likes vs. Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='likes', y='views')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likes vs. Views with the Category Id as a color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='likes', y='views', color='category_id')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likes vs. Views with the Category Id as a color, plus a linear regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='likes', y='views', color='category_id', trendline='ols')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likes vs. comment_count with the Category Id as a color, plus a linear regression line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, ???)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Faceting </h3>\n",
    "\n",
    "Faceting partitions a plot into a matrix of panels. Each panel shows a different subset of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data, x='likes', y='views', trendline='ols', facet_col='category_id')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there's way too many categories displayed here to figure out what's happening. Let's look at just 3 different categories by querying our data (more on queries later). You'll also see we used the `hover_data` argument to display the channel title when we hover over a point. \n",
    "\n",
    "What interesting patterns (or lack thereof) do you see between the different categories and channels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.scatter(data.query(\"category_id==1 | category_id==2 | category_id==10\"), x='likes', y='views', trendline='ols', hover_data=['channel_title'], facet_col='category_id')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> 3D Plots </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line_3d(data, x=\"likes\", y=\"views\", z=\"comment_count\", color=\"category_id\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also add Text and Annotations to our plots with the `update_layout` function. We'll just add a title here, but you can read the documentation if you want to learn more.\n",
    "\n",
    "[Documentation: Plotly Text and Annotations](https://plot.ly/python/text-and-annotations/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.line_3d(data, x=\"likes\", y=\"views\", z=\"comment_count\", color=\"category_id\")\n",
    "fig.update_layout(title_text='3D Plot of Likes, Views, and Comment Count')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Manipulating our Dataset </h3>\n",
    "\n",
    "Quick Reference: [Data Wrangling with pandas Cheat Sheet](https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pandas groupby </h4>\n",
    "\n",
    "The `groupby()` function groups the supplied dataframe by the unique values of the column(s) you supply. \n",
    "\n",
    "Typically, when using `groupby()` you group the data, apply some function (like `sum()` or `count()`), then combine it to see the results. \n",
    "\n",
    "[Documentation: pandas.DataFrame.groupby()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.groupby.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_videos_by_category = data.groupby('category_id').count()\n",
    "count_videos_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep 'category_id' as a regular column and not an index, set the `as_index` parameter to `False`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_videos_by_category = data.groupby('category_id', as_index=False).count()\n",
    "count_videos_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What video categories have the most views or likes? (or dislikes!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data_by_category = data.groupby('category_id', as_index=False).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pandas sort_values </h4>\n",
    "\n",
    "Hard to tell exactly though, let's sort it.\n",
    "\n",
    "[Documentation: pandas.DataFrame.sort_values](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.sort_values.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data_by_category = summed_data_by_category.sort_values('views')\n",
    "summed_data_by_category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting closer! I'm more interested in the most views, so we should sort descending instead of the default ascending. We can do this by setting the `ascending` parameter of the `sort_values` function to `False`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summed_data_by_category = summed_data_by_category.sort_values('views', ascending=False)\n",
    "summed_data_by_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(summed_data_by_category, x='category_id', y='views')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is great, but again, we'd also like to see this sorted. Thankfully, we can use `update_layout` on the figure to set the x-axis to be a categorical variable and `update_xaxes` to set the category order to descending."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(summed_data_by_category, x='category_id', y='views')\n",
    "fig.update_layout(xaxis_type='category')\n",
    "fig.update_xaxes(categoryorder=\"total descending\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pandas - Subsetting and Slicing Data </h4>\n",
    "\n",
    "The `query()` function subsets your dataframe to only the rows that meet your query. You write queries on the columns. \n",
    "\n",
    "[Documentation: pandas.DataFrame.query()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.query.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take out videos that have ratings diabled. They may be throwing off our analysis since their likes and dislikes are 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.query('ratings_disabled == False')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Yourself: Get Videos with more than 10,000,000 views\n",
    "lots_of_views = ???\n",
    "lots_of_views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also do queries on multiple columns at once. You can combine queries using `&` (and) or `|` (or).\n",
    "\n",
    "Let's look at videos that have 'category_id' = 1 and 'comments_disabled' as `True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "data.query('???')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pandas - Selecting Columns </h4>\n",
    "\n",
    "To select a column in a dataframe:\n",
    "    `df['my_column_name']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Pandas - Creating New Columns </h4>\n",
    "\n",
    "Let's create a column containing the length of the title for each video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['title_length'] = data['???'].str.len()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do the number of likes on a video compare to its number of views?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['percent_likes'] = data['likes'] / data['views']\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can look again at the correlation of the columns, now that we have our new variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There does not appear to be any obvious correlation with our new variables and other variables. However, this doesn't necessarily mean there aren't any relationships between them. Pearson's correlation only looks at linear relationships between variables. Additionally, if we look at different subsets of our videos, we may or may not find linear correlations or other nonllinear relationships that hold for that subset. \n",
    "\n",
    "This is the idea behind EDA. There is *so much* that we can look at in a dataset. Some things we try will yield interesting results, whereas other ideas will be deadends. Happy exploring!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
