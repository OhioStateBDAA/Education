{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1> Machine Learning in Python <h1>\n",
    "    <img src=\"https://bdaaosu.org/static/img/Logo.png\" width=\"40%\"> </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was prepared and created by [Leo Glowacki](http://www.leoglowacki.com). Any questions can be sent through (preferably) the BDAA slack or through the <a href=\"http://www.leoglowacki.com/contact\">contact form on my website</a>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Importing Packages </h3>  \n",
    "\n",
    "First things first- importing packages. We'll be using:\n",
    "\n",
    "[Pandas](http://pandas.pydata.org/) - library for data manipulation and analysis\n",
    "\n",
    "[Scikit-Learn](https://scikit-learn.org/stable/) - super popular package for ML in python (we'll see why!)\n",
    "\n",
    "You will likely need to add python-graphviz to your Anaconda environment. Most common data science packages come included with Anaconda, however, python-graphviz not included. We'll do this together. ([Instructions if you need them later](https://www.tutorialspoint.com/add-packages-to-anaconda-environment-in-python)) \n",
    "\n",
    "If you are having any issues intalling or updating packages in your Anaconda environment, this is a reported issue. Luckily, there is a [fix (scroll to bottom)](https://github.com/ContinuumIO/anaconda-issues/issues/9087). Ask a TA if you need help! It can be a little confusing if you haven't worked with Anaconda before. \n",
    "\n",
    "(Alternatively install with: \n",
    "> conda install python-graphviz\n",
    "\n",
    "But if shell comands are intimitdating to you, no worries, just follow along and ask a TA if you need help)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing pandas\n",
    "import pandas as pd\n",
    "\n",
    "# packages used for graphing decision trees\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image  \n",
    "import pydotplus\n",
    "\n",
    "# Scikit-Learn \n",
    "# This package is huge, so we only want to import what we're going to use\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use this function later to graph our decision tress. Feel free to use this code in your own projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_decision_tree(dt):\n",
    "    # Create DOT data\n",
    "    dot_data = export_graphviz(dt, out_file=None,  \n",
    "                    filled=True, rounded=True,\n",
    "                    special_characters=True, feature_names = feature_names, class_names= class_names)\n",
    "\n",
    "    # Draw graph\n",
    "    graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "\n",
    "    # Show graph\n",
    "    return Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this first part, we're going to be using a somewhat 'famous' mushrooms dataset\n",
    "\n",
    "[Dataset Info](https://www.kaggle.com/uciml/mushroom-classification)\n",
    "\n",
    "[Download Link](https://www.kaggle.com/uciml/mushroom-classification/download/FMiTAKyaW7e7uQijwjGk%2Fversions%2FegC1k5tVZm5ghrgU3maT%2Ffiles%2Fmushrooms.csv)\n",
    "\n",
    "[Documentation: pandas.read_csv()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our CSV file as a pandas dataframe called 'df'\n",
    "# you will often see pandas dataframes called 'df'\n",
    "df = pd.read_csv(\"mushrooms.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is being considered an 'object', but really, it's a categorical variable. Let's fix that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"mushrooms.csv\", dtype='category')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our features, we want to use everything, *except* our class variable (what we're trying to predict).\n",
    "\n",
    "[Documentation: pandas.Dataframe.drop()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.drop.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec = df.drop(['class'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have selected our feature vector, we need to change it to a form that Decision Trees can use. Since DTs use numbers and not letters, we need to transform our data into 0s and 1s it can interpret.\n",
    "\n",
    "[Documentation: pandas.get_dummies()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vec = pd.get_dummies(feature_vec)\n",
    "feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our features, or our 'feature vector'\n",
    "X = feature_vec\n",
    "# Y is our labels\n",
    "Y = df['class']\n",
    "\n",
    "feature_names = list(X.columns)\n",
    "class_names = df['class'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(feature_names)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into our training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "### Decision Tree: Take One\n",
    "\n",
    "To grow a Decision Tree, we initialize the Decision Tree, then 'fit' it to our training data.  \n",
    "\n",
    "[Documentation: DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=2)\n",
    "# train it oun our training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've built our decision tree, let's see what it looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_decision_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GINI is a measure of impurity. A node is \"pure\" if gini=0. The higher the GINI score, the more \"disorganized\" the classes in the node are. \n",
    "\n",
    "Food for thought: What does odor being at the top of the tree indicate about it's ability to predict whether a mushroom is poisonous or edible?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well does the Decision Tree predict observations it was trained on?\n",
    "\n",
    "\n",
    "[Documentation: Scikit-learn Accuracy](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Trainnig Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok that's great, we probably won't accidentally poison ourselves if we come across a mushroom we have in our training set, but what about new mushrooms?  To get an estimate of how well our model will perform, we can the testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is about the same as the training accuracy. This is good. It means our model has probably not overfit the training data. \n",
    "\n",
    "Can we do any better though? Let's see what happens if we increase the depth of our tree."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Take Two (Deeper Tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initalize Decision Tree\n",
    "dt = DecisionTreeClassifier(max_depth=4)\n",
    "# train it oun our training set\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_decision_tree(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Trainnig Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = dt.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even better! \n",
    "\n",
    "But how do we know what the best value for our hyperparameter `max_depth`? Can we automate this process?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree: Take 3 (Automated Hyperparameter Selection)\n",
    "[Documentation: sklearn.model_selection.GridSearchCV()](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hyper-parameters you want to test\n",
    "params = {'max_depth': list(range(1, 25))}\n",
    "# initiate Grid Search Crossfold Validator for a Decision Tree\n",
    "grid_search_cv = GridSearchCV(DecisionTreeClassifier(), params, verbose=1, cv=3)\n",
    "# train the grid search cv\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_decision_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \"Final\" Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see how accurate it is on observations it has never 'seen' or had it's hyperparameters tuned with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Testing Accuracy\n",
    "y_pred = dt.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We would likely fair very well if we used this is the wild (assuming our data is representative of mushrooms we might find in the wild). \n",
    "\n",
    "**DISCLAIMER: Don't try this at home kids.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your Turn! \n",
    "\n",
    "Remember the \"USVideos.csv\" dataset from the EDA workshop last week? Let's see if we can predict the category of the video based on its features (likes, dislikes, views, etc.). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get the data\n",
    "\n",
    "[Dataset Info](https://www.kaggle.com/datasnaek/youtube-new#USvideos.csv)\n",
    "\n",
    "[Download the Dataset Here](https://www.kaggle.com/datasnaek/youtube-new/download/ZGIimwlwh1EQ13BoyAyJ%2Fversions%2FHaqpEW6xcYnw6T0JDLWk%2Ffiles%2FUSvideos.csv?datasetVersionNumber=115)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the CSV file\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view your dataframe to make sure everything imported as intended\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Data Cleaning & Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the column data types in the dataframe\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fix a few columns to be the proper data types\n",
    "\n",
    "# fixing 'trending_date' and 'publish_time' to be dates\n",
    "df['trending_date'] = pd.to_datetime(df['trending_date'],format='%y.%d.%m')\n",
    "df['publish_time'] = pd.to_datetime(df['publish_time'])\n",
    "# making 'category_id' a categorical (factor) variable\n",
    "df['category_id'] = df['category_id'].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check to see if the typecasting worked\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Last time in our EDA, we created a couple variables. Let's recreate them here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create variable title length\n",
    "df['title_length'] = df['title'].str.len()\n",
    "# create variable percent likes\n",
    "df['percent_likes'] = df['likes'] / df['views']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see our new variables\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create our input feature vector and label vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X is our features, or our 'feature vector'\n",
    "# we need to limit X to numerical and boolean columns\n",
    "feature_names = ['views', 'likes', 'dislikes', 'comments_disabled', 'comment_count', 'comments_disabled', 'ratings_disabled', 'video_error_or_removed', 'title_length', 'percent_likes']\n",
    "class_names = [str(i) for i in df['category_id'].unique()]\n",
    "X = df[feature_names]\n",
    "# Y is our labels\n",
    "Y = df['category_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into our training and test set\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hyper-parameters you want to test\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# initiate Grid Search Crossfold Validator for a Decision Tree\n",
    "grid_search_cv = # YOUR CODE HERE\n",
    "\n",
    "# train the grid search cv\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the grid search cv\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: \"Final\" Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Training Accuracy\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Test Accuracy\n",
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Take One - Simple RF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=100)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Training Accuracy\n",
    "y_pred = rf.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Train Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Test Accuracy\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wow! This is already a huge performance boost!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest: Choosing the 'Best' Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary of hyper-parameters you want to test\n",
    "params = {'n_estimators': [100, 125, 150], \n",
    "          'max_depth': [40, 45, 50], \n",
    "          'min_samples_split': [2]}\n",
    "# initiate Grid Search Crossfold Validator for a Decision Tree\n",
    "grid_search_cv = GridSearchCV(RandomForestClassifier(), params, verbose=1, cv=3)\n",
    "\n",
    "grid_search_cv.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_cv.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Training Accuracy\n",
    "y_pred = rf.predict(X_train)\n",
    "accuracy = metrics.accuracy_score(y_train, y_pred)\n",
    "print(\"Train Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reporting Test Accuracy\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many other parameter combinations we could test to try and improve the accuracy (as well as other metrics besides accuracy we could use to determine the best model), but this is a good start. Go forth and learn! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
